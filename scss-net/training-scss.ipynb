{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834afca-e92c-4079-ba95-54f92ceea6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/space-lab-sk/scss-net.git\n",
    "#%cd scss-net\n",
    "#!git pull origin main                # uncomment and start here if the repo is already cloned\n",
    "!pip install -U pip\n",
    "!pip install -U setuptools\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858ef7b-4b2d-40f2-bd12-74491c340612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append('../scss-net/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13479fb2-2bae-43e3-8317-864beb7cf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mega import Mega\n",
    "import zipfile\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations\n",
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e15d6-d5bc-4555-b2ed-07792bf4dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_scss_net import scss_net\n",
    "from metrics import dice_np, iou_np, dice, iou\n",
    "from utils import plot_imgs, plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a289ae-3011-43f6-87b9-ed9a5d9c19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6cc89-842b-4931-9fac-adb534ebbc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64  # resize imgs to 256x256\n",
    "BATCH_SIZE = 20 # set batch size\n",
    "SEED = 20       # set seed for reproducibility\n",
    "EPOCHS = 1000    # Set number of epochs\n",
    "\n",
    "MODEL_NAME = \"model_galaxie_vsetky_1000_ep_drop_6\"                       # Specify model name\n",
    "model_filename = f\"{MODEL_NAME}.h5\"                # Specify path where to save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57811457-c84a-4132-98cc-d62bf9c69b32",
   "metadata": {},
   "source": [
    "## DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7e124-9b8b-419a-8776-4b0abdb7a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob.glob(\"data/all_galaxies/*.jpg\")\n",
    "masks = glob.glob(\"data/all_masks/*.jpg\")\n",
    "\n",
    "print(f\"Imgs number = {len(imgs)}\\nMasks number = {len(masks)}\")\n",
    "\n",
    "imgs_list = []\n",
    "masks_list = []\n",
    "for image, mask in zip(imgs, masks):\n",
    "    #ig = Image.open(image)\n",
    "    #enhancer = ImageEnhance.Color(ig)\n",
    "    #enhancer.enhance(25) toto namiesto Image.open(image)\n",
    "    imgs_list.append(np.array(Image.open(image).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))))\n",
    "    masks_list.append(np.array(Image.open(mask).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c98420-5a7f-4816-9dd1-ff155f08f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization from (0; 255) to (0; 1)\n",
    "x = np.asarray(imgs_list, dtype=np.float32)/255\n",
    "y = np.asarray(masks_list, dtype=np.float32)/255\n",
    "\n",
    "# Reshape to (n_imgs, height, width, channels)\n",
    "x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "y = y.reshape(y.shape[0], y.shape[1], y.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522d310-5021-457b-8c87-a75d13dd2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22eccae-b0c3-4497-9ae6-d4ed8c120730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0b271-55ee-40aa-b635-ce38e5f6106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(imgs=x, masks=y, n_imgs=8).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93396b-8776-483f-ae64-f766023bb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape should be (256, 256, 1)\n",
    "input_shape = x_train[0].shape\n",
    "print(f\"Input shape: {input_shape}\\nTrain shape: {x_train.shape}  Val shape: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4646ab6-6b11-41c5-827a-19828d9c4135",
   "metadata": {},
   "source": [
    "## TRAINING SCSS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fd5ae-5102-46f3-a709-8e04ac1f9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture with optimal parameteres\n",
    "model = scss_net( \n",
    "    input_shape,\n",
    "    filters=32,       \n",
    "    layers=4,\n",
    "    batch_norm=True,\n",
    "    drop_prob=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565fc9d-e140-46c8-9cb8-7ec5fce124f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",  \n",
    "    metrics=[iou, dice])\n",
    "\n",
    "# Set steps parameters acording to size of training set and size of batch\n",
    "STEPS = x_train.shape[0] // BATCH_SIZE        \n",
    "\n",
    "# Set Callback that saves only best weights\n",
    "callback_checkpoint = ModelCheckpoint(\n",
    "    model_filename,\n",
    "    verbose=1,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed55921-3654-4b04-a44d-6175da6bd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_galaxie_vsetky_1000_ep.h5\") # TRENUJEME ODZNOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac369bd-b1e3-4e99-bd8c-cfc3f981badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "#history = model.fit(\n",
    "#    x_train,\n",
    "#    y_train,\n",
    "#    steps_per_epoch=STEPS,\n",
    "#    epochs=EPOCHS,\n",
    "#    validation_data=(x_val, y_val),\n",
    "#    callbacks=[callback_checkpoint],\n",
    "#    verbose=2)\n",
    "\n",
    "# # Plot training history (Metrics and Loss)\n",
    "#plot_metrics(history).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb0ec3-f987-40f9-bb66-64bd18d7e209",
   "metadata": {},
   "source": [
    "cca 22 hodin na macbook pro m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bb8b0-bbe1-4ade-b4b1-32ebd3afa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe264d-995a-4920-a72f-3753e106ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed433532-493c-4a82-ada4-aec64bf9e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(imgs=x_val, masks=y_val, predictions=y_pred, n_imgs=5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d9982-0611-40c0-93e6-c16e0e00a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = glob.glob(\"data/testovacia_po_edge_detection/cropped_improved_galaxies/*.jpg\")\n",
    "masks_test = glob.glob(\"data/testovacia_po_edge_detection/galaxy_improved_masks/*.jpg\")\n",
    "\n",
    "print(f\"Imgs number = {len(imgs_test)}\\nMasks number = {len(masks_test)}\")\n",
    "\n",
    "# Load data and convert imgs to np.array\n",
    "imgs_test_list = []\n",
    "masks_test_list = []\n",
    "for image, mask in zip(imgs_test, masks_test):\n",
    "    imgs_test_list.append(np.array(Image.open(image).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))))\n",
    "    masks_test_list.append(np.array(Image.open(mask).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))))\n",
    "\n",
    "# Normalization from (0; 255) to (0; 1)\n",
    "x_test = np.asarray(imgs_test_list, dtype=np.float32)/255\n",
    "y_test = np.asarray(masks_test_list, dtype=np.float32)/255\n",
    "\n",
    "# Reshape to (n_imgs, height, width, channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1], y_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784614cb-234b-487e-b9fa-9955505b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)  \n",
    "plot_imgs(imgs=x_test, masks=y_test, predictions=y_pred, n_imgs=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eec8a1-d970-4b5f-9f92-5b34611fde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "for tresh in range(10, 100 + step, step):\n",
    "    test_tresh = tresh / 100\n",
    "    y_pred_bin = np.where(y_pred > test_tresh, 1, 0)  # Set threshold for predicted values\n",
    "\n",
    "    dice = np.round(dice_np(y_val, y_pred), 4)\n",
    "    iou_val = np.round(iou_np(y_val, y_pred), 4)\n",
    "\n",
    "    dice_tresh = np.round(dice_np(y_val, y_pred_bin), 4)\n",
    "    iou_val_tresh = np.round(iou_np(y_val, y_pred_bin), 4)\n",
    "\n",
    "    print(f\"Validation (> {test_tresh}):\\nDice: {dice} Dice_tresh: {dice_tresh}\\n IoU: {iou_val} IoU_tresh: {iou_val_tresh}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033411c2-a5c8-4a7f-96c9-2fd98d1580e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)  \n",
    "plot_imgs(imgs=x_test, masks=y_test, predictions=y_pred, n_imgs=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4840f6-47b5-4066-b83c-abe98e3c9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin = np.where(y_pred > 0.5, 1, 0)  # Set threshold for predicted values\n",
    "\n",
    "dice = np.round(dice_np(y_val, y_pred), 4)\n",
    "iou_val = np.round(iou_np(y_val, y_pred), 4)\n",
    "\n",
    "dice_tresh = np.round(dice_np(y_val, y_pred_bin), 4)\n",
    "iou_val_tresh = np.round(iou_np(y_val, y_pred_bin), 4)\n",
    "\n",
    "print(f\"Validation:\\nDice: {dice} Dice_tresh: {dice_tresh}\\n IoU: {iou_val} IoU_tresh: {iou_val_tresh}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afaf88-214b-4dd3-a4ec-bb0ed3772ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "for tresh in range(10, 100 + step, step):\n",
    "    test_tresh = tresh / 100\n",
    "    y_pred_bin = np.where(y_pred > test_tresh, 1, 0)  # Binarize predicted values\n",
    "\n",
    "    dice = np.round(dice_np(y_test, y_pred), 4)\n",
    "    iou_test = np.round(iou_np(y_test, y_pred), 4)\n",
    "\n",
    "    dice_tresh = np.round(dice_np(y_test, y_pred_bin), 4)\n",
    "    iou_test_tresh = np.round(iou_np(y_test, y_pred_bin), 4)\n",
    "\n",
    "    print(f\"Validation (> {test_tresh}):\\nDice: {dice} Dice_tresh: {dice_tresh}\\n IoU: {iou_test} IoU_tresh: {iou_test_tresh}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d70065",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_resized = []\n",
    "for i, pred in enumerate(y_pred):\n",
    "    # Remove channel dimension if necessary\n",
    "    # mask = np.squeeze(pred)\n",
    "    \n",
    "    # Convert from [0,1] to [0,255] and ensure type is uint8\n",
    "    # mask = (mask).astype(np.uint8)* 255\n",
    "    \n",
    "    # Retrieve the original size; note that PIL's img.size returns (width, height)\n",
    "    orig_size = original_shapes[i]\n",
    "    \n",
    "    # Resize the mask back to the original size using nearest-neighbor interpolation\n",
    "    resized_mask = cv2.resize(pred, orig_size, interpolation=cv2.INTER_NEAREST)\n",
    "    y_pred_resized.append(resized_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6f2ab-c486-4bb9-b255-29b1358f6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_masks(y_pred, input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Reads image filenames from a folder and saves predicted masks with the same names.\n",
    "\n",
    "    :param numpy.array y_pred: Array of predicted masks.\n",
    "    :param str input_folder: Folder containing original images.\n",
    "    :param str output_folder: Folder to save predicted masks.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get all image filenames from the input folder\n",
    "    image_filenames = sorted([\n",
    "        f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "\n",
    "    if len(image_filenames) != len(y_pred):\n",
    "        print(f\"Warning: {len(image_filenames)} images but {len(y_pred)} masks!\")\n",
    "    \n",
    "    for pred_mask, img_filename in zip(y_pred, image_filenames):\n",
    "        filename = os.path.splitext(img_filename)[0]  # Remove extension\n",
    "        mask_filename = os.path.join(output_folder, f\"{filename}.png\")\n",
    "\n",
    "        # Convert mask to 8-bit grayscale (0-255)\n",
    "        pred_mask = (pred_mask * 255).astype(np.uint8)\n",
    "\n",
    "        # Save the mask\n",
    "        cv2.imwrite(mask_filename, pred_mask)\n",
    "        print(f\"Saved: {mask_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"../../data/new_data_subset/masks_from_cut_fits/masks_scss\"\n",
    "input_folder = \"../../data/new_data_subset/masks_from_cut_fits/images_dump/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predicted_masks(y_pred_resized, input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
